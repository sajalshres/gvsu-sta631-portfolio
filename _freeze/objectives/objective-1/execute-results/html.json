{
  "hash": "2fca20656794c823f31d824fcce2cacc",
  "result": {
    "markdown": "---\ntitle: \"Objective 1\"\n---\n\n\n## Probability as a foundation of statistical modeling\n\nCourse Objective:\n\n> Describe probability as a foundation of statistical modeling, including inference and maximum likelihood estimation\n\nProbability is a fundamental concept in statistical modeling, providing a quantitative measure of the likelihood of an event occurring within a given set of possible outcomes. It plays a vital roles in various aspects of statistics, including inference and maximum likelihood estimation.\n\nSome basic examples to illustrate probability distributions, statistical modeling, inference, and maximum likelihood estimations includes:\n\n### 1. Probabitlity Distributions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Uniform distribution\nmin <- 0 # lower limit\nmax <- 1 # upper limit\n\n# Generate 1000 random numbers from a uniform distribution\nx <- runif(1000, min = min, max = max)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(631)\n\n# Generate a sample dataset.\nx <- seq(1, 100)\n# True relationship: y = 2x + noise\ny <- 2 * x + rnorm(100, mean = 0, sd = 10)\n\n# Fit linear regression model\nmodel <- lm(y ~ x)\n\n# Model summary\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.8503  -8.1615  -0.3714   7.7412  27.5390 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.79709    2.17457   1.286    0.201    \nx            1.93288    0.03738  51.703   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.79 on 98 degrees of freedom\nMultiple R-squared:  0.9646,\tAdjusted R-squared:  0.9643 \nF-statistic:  2673 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### 2. Statistical Modeling - Linear Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\n\n# Generate sample dataset\nx <- seq(1, 100)\n# true relationship: y = 2x + noise\ny <- 2 * x + rnorm(100, mean = 0, sd = 10)\n\n# Fit linear regression model\nmodel <- lm(y ~ x)\n\n# Model summary\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-30.195  -6.618   0.809   6.527  22.264 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.68935    2.10869   0.327    0.744    \nx            1.99279    0.03625  54.971   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.46 on 98 degrees of freedom\nMultiple R-squared:  0.9686,\tAdjusted R-squared:  0.9683 \nF-statistic:  3022 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### 3. Inference - Confidence Interval and Hypothesis Testing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Confidence interval\nconf_int <- confint(model, level = 0.95)  # 95% confidence interval for model parameters\nprint(conf_int)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                2.5 %   97.5 %\n(Intercept) -3.495271 4.873967\nx            1.920848 2.064729\n```\n:::\n\n```{.r .cell-code}\n# Hypothesis testing (t-test)\nt_test <- summary(model)$coefficients  # t-test results for model coefficients\nprint(t_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Estimate Std. Error    t value     Pr(>|t|)\n(Intercept) 0.689348 2.10868611  0.3269088 7.444341e-01\nx           1.992788 0.03625174 54.9708280 1.861790e-75\n```\n:::\n:::\n\n\n### 4. Maximum Likelihood Estimation - Logistic Regression:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate data\nset.seed(42)\nx <- rnorm(100)\nz <- 1 + 2 * x\nprob <- 1 / (1 + exp(-z))\ny <- rbinom(100, size = 1, prob = prob)  # binary response variable\n\n# Fit logistic regression model using maximum likelihood estimation\nmodel <- glm(y ~ x, family = binomial(link = \"logit\"))\n\n# Model summary\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = y ~ x, family = binomial(link = \"logit\"))\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.1367     0.3598   3.159  0.00158 ** \nx             3.1979     0.6610   4.838 1.31e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 129.489  on 99  degrees of freedom\nResidual deviance:  61.527  on 98  degrees of freedom\nAIC: 65.527\n\nNumber of Fisher Scoring iterations: 6\n```\n:::\n:::\n\n\nThe above example demonstrate working with probability distributions, fitting statistical models, perform inference and apply maximum likelihood estimation in the context of linear and logistic regression.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}